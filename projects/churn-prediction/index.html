<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Shadow Tracker: Analyzing User Behavior in Dark Pools and Detecting Anti-Forensics with Tor, VPN, and Memory Analysis">
    <meta name="keywords" content="user behavior forensics, dark pools, Tor, VPN, anti-forensics, cybersecurity, data analysis, digital forensics">
    <meta name="author" content="[Your Name]">
    <title>Shadow Tracker | [Your Name]</title>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="./style.css">
</head>
<body>
    <!-- Navigation with Back Link -->
    <header class="header">
        <div class="container">
            <div class="logo">
                <span class="logo-highlight">[Your Initial]</span>[Your Name]
            </div>
            <nav class="nav">
                <ul>
                    <li><a href="../../index.html" class="nav-link">Back to Home</a></li>
                </ul>
            </nav>
        </div>
    </header>

    <!-- Main Section -->
    <section class="section">
        <div class="container">
            <h1 class="section-title">Shadow Tracker: Analyzing User Behavior in Dark Pools</h1>

            <!-- Introduction -->
            <p class="intro-text">
                Shadow Tracker is an investigative cybersecurity project that dives into user behavior forensics within privacy-centric environments like Tor and VPNs. By analyzing digital artifacts such as browser cache, VPN logs, memory dumps, and traces of anti-forensic tools, it profiles user activities, detects anomalies, and uncovers attempts to hide digital footprints.
            </p>
            <p class="intro-text">
                The system simulates a digital forensics investigation, parsing artifacts to reconstruct user actions, identifying suspicious patterns (e.g., short Tor sessions, unusual IP changes), and detecting anti-forensic actions (e.g., cache clearing with CCleaner). Results are visualized through timelines, heatmaps, and network graphs, with a forensic report ensuring evidential integrity.
            </p>
            <p class="intro-text">
                This project is relevant to cybercrime investigations, threat intelligence, and Digital Forensics and Incident Response (DFIR), showcasing skills in cybersecurity, data analysis, and machine learning.
            </p>

            <!-- Technologies Used -->
            <h2 class="subtitle">Technologies Used</h2>
            <div class="tech-stack">
                <ul>
                    <li><strong>Python</strong>: Core language for artifact parsing, data analysis, and ML modeling.</li>
                    <li><strong>SQLite3</strong>: Parsing Tor Browser’s <code>places.sqlite</code> for browsing history.</li>
                    <li><strong>Volatility3</strong>: Memory analysis for Tor/VPN processes and network connections.</li>
                    <li><strong>Pandas & NumPy</strong>: Data aggregation, statistical analysis, and preprocessing.</li>
                    <li><strong>Plotly & Seaborn</strong>: Visualizations like timelines, heatmaps, and scatter plots.</li>
                    <li><strong>PyVis</strong>: Network graphs for visualizing Tor node connections.</li>
                    <li><strong>Scikit-learn</strong>: Anomaly detection using Isolation Forest.</li>
                    <li><strong>ReportLab</strong>: Generating forensic reports in PDF format.</li>
                    <li><strong>Hashlib</strong>: Computing MD5/SHA256 hashes for evidence integrity.</li>
                </ul>
            </div>
            <p>
                These tools were chosen for their robustness in digital forensics, data science, and visualization, ensuring a scalable and reproducible workflow.
            </p>

            <h2 class="subtitle">1. Setting Up the Environment</h2>
            <p>
                The project began with configuring a controlled environment to simulate privacy-centric user activities. A virtual machine running Windows 10 and Ubuntu 20.04 was set up using VirtualBox to ensure isolation and repeatability.
            </p>
            <ul>
                <li><strong>Tor Browser</strong>: Installed to generate browsing artifacts, with the profile folder (<code>~/.tor-browser/profile</code> on Linux) used for cache analysis.</li>
                <li><strong>OpenVPN</strong>: Configured with a sample VPN provider to simulate encrypted connections, logging enabled for analysis.</li>
                <li><strong>Volatility3</strong>: Installed from GitHub, configured with plugins for Windows and Linux memory analysis.</li>
                <li><strong>Python Environment</strong>: Created a virtual environment with Python 3.9, installing libraries like <code>pandas</code>, <code>scikit-learn</code>, and <code>volatility3</code>.</li>
            </ul>
            <p>
                To test the setup, I launched Tor Browser, connected to a VPN, and created a memory dump using <code>dumpit</code> on Windows. This ensured all components were ready for artifact collection.
            </p>
            <img src="images/tor_setup.jpg" alt="Terminal showing Tor Browser and OpenVPN running" class="project-img">
            <p>
                <strong>Challenge</strong>: Initial issues with Volatility3 due to missing memory dump plugins.<br>
                <strong>Solution</strong>: Updated Volatility3 to the latest version and used the correct memory profile (<code>Win10x64_19041</code>) for analysis.
            </p>

            <h2 class="subtitle">2. Collecting and Parsing Artifacts</h2>
            <p>
                Artifacts were collected from multiple sources to capture a comprehensive view of user behavior. Each source required a custom Python script for parsing, ensuring data was extracted accurately and efficiently.
            </p>
            <ul>
                <li><strong>Tor Browser Cache</strong>: The <code>places.sqlite</code> database in the Tor profile folder was parsed using <code>sqlite3</code> to extract browsing history, including URLs and visit timestamps.</li>
                <li><strong>VPN Logs</strong>: OpenVPN logs (<code>/var/log/openvpn.log</code> on Linux, Event Logs on Windows) were parsed to identify connection times, IP addresses, and session durations.</li>
                <li><strong>Memory Analysis</strong>: Volatility3 was used to analyze memory dumps, identifying processes (e.g., <code>tor.exe</code>) and network connections (<code>netscan</code> plugin).</li>
                <li><strong>Anti-Forensics Traces</strong>: Windows registry keys (<code>HKCU\Software\CCleaner</code>) and file system changes (e.g., <code>$Recycle.Bin</code>) were analyzed to detect tools like CCleaner.</li>
            </ul>
            <p>
                Example code for parsing Tor’s <code>places.sqlite</code>:
            </p>
            <pre><code>import sqlite3
from datetime import datetime

def convert_tor_timestamp(microseconds):
    return datetime.fromtimestamp(microseconds / 1000000.0)

conn = sqlite3.connect("places.sqlite")
cursor = conn.cursor()
cursor.execute("SELECT url, visit_date FROM moz_places JOIN moz_historyvisits ON moz_places.id = moz_historyvisits.place_id")
rows = cursor.fetchall()
history = [{"url": row[0], "visit_date": convert_tor_timestamp(row[1])} for row in rows]
conn.close()
            </code></pre>
            <p>
                This script extracted URLs and timestamps, which were later used for behavioral profiling.
            </p>
            <img src="images/sqlite_output.jpg" alt="Python script output showing parsed Tor browsing history" class="project-img">
            <p>
                <strong>Challenge</strong>: Corrupted <code>places.sqlite</code> files due to improper Tor shutdowns.<br>
                <strong>Solution</strong>: Validated database integrity with <code>sqlite3.pragma_integrity_check</code> and ensured clean Tor sessions.
            </p>

            <h2 class="subtitle">3. Building Behavioral Profiles</h2>
            <p>
                Behavioral profiles were created by aggregating artifact data into meaningful patterns. Using <code>pandas</code>, I analyzed session times, browsing frequency, and system changes to establish a baseline of normal user behavior.
            </p>
            <ul>
                <li><strong>Session Analysis</strong>: Calculated average session duration and frequency of Tor/VPN usage.</li>
                <li><strong>Browsing Patterns</strong>: Identified unique domains and visit counts from Tor’s cache.</li>
                <li><strong>System Changes</strong>: Tracked file system and registry modifications to detect potential anti-forensic actions.</li>
            </ul>
            <p>
                Example code for session analysis:
            </p>
            <pre><code>import pandas as pd

history_df = pd.DataFrame(history)
history_df["visit_date"] = pd.to_datetime(history_df["visit_date"])
history_df["hour"] = history_df["visit_date"].dt.hour
hourly_activity = history_df.groupby("hour").size().to_frame(name="visits")
            </code></pre>
            <p>
                This code generated a DataFrame with hourly browsing activity, which was visualized as a heatmap to highlight peak usage times.
            </p>
            <img src="images/profile_heatmap.jpg" alt="Seaborn heatmap showing Tor session activity by hour" class="project-img">
            <p>
                <strong>Challenge</strong>: Inconsistent timestamps across artifacts (e.g., Tor vs. VPN logs).<br>
                <strong>Solution</strong>: Normalized all timestamps to UTC using <code>pandas.to_datetime</code>.
            </p>

            <h2 class="subtitle">4. Detecting Anomalies</h2>
            <p>
                Anomalies were detected using a combination of rule-based flags and a machine learning model. Rules flagged obvious suspicious behaviors, while ML identified subtle deviations from normal patterns.
            </p>
            <ul>
                <li><strong>Rule-Based Detection</strong>: Flagged sessions shorter than 1 minute or with >5 IP changes per hour.</li>
                <li><strong>ML Detection</strong>: Trained an Isolation Forest model on features like session length, IP changes, and browsing frequency.</li>
            </ul>
            <p>
                Example code for ML anomaly detection:
            </p>
            <pre><code>from sklearn.ensemble import IsolationForest

features = history_df[["session_length", "ip_changes"]]
model = IsolationForest(contamination=0.1, random_state=42)
history_df["anomaly"] = model.fit_predict(features)
anomalies = history_df[history_df["anomaly"] == -1]
            </code></pre>
            <p>
                The model flagged outliers, which were visualized as scatter plots to highlight suspicious sessions.
            </p>
            <img src="images/anomaly_plot.jpg" alt="Plotly scatter plot showing detected anomalies in session data" class="project-img">
            <p>
                <strong>Challenge</strong>: Overfitting in the ML model due to imbalanced feature scales.<br>
                <strong>Solution</strong>: Applied <code>StandardScaler</code> to normalize features and tuned the <code>contamination</code> parameter.
            </p>

            <h2 class="subtitle">5. Detecting Anti-Forensics</h2>
            <p>
                Anti-forensic actions, such as cache clearing or system cleaning, were detected by analyzing specific artifacts. For example, CCleaner usage was identified through registry keys, and file deletions were tracked in <code>$Recycle.Bin</code>.
            </p>
            <p>
                Example code for registry analysis:
            </p>
            <pre><code>from winreg import *

key = OpenKey(HKEY_CURRENT_USER, r"Software\CCleaner")
cleaner_used = QueryValueEx(key, "LastUsed")[0]
CloseKey(key)
            </code></pre>
            <p>
                This script checked if CCleaner was recently used, indicating potential anti-forensic activity.
            </p>
            <img src="images/registry_output.jpg" alt="Python output showing CCleaner registry key analysis" class="project-img">
            <p>
                <strong>Challenge</strong>: Limited visibility into anti-forensic tools on Linux.<br>
                <strong>Solution</strong>: Focused on Windows artifacts and supplemented with file system analysis (<code>stat</code> command on Linux).
            </p>

            <h2 class="subtitle">6. Visualizing Data</h2>
            <p>
                Visualizations were critical for interpreting complex forensic data. I created three types of visualizations to present findings clearly:
            </p>
            <ul>
                <li><strong>Timeline</strong>: Chronological view of user actions (e.g., browsing, VPN connections) using Plotly.</li>
                <li><strong>Heatmap</strong>: Hourly activity patterns using Seaborn to identify peak usage times.</li>
                <li><strong>Network Graph</strong>: Connections between IPs and Tor nodes using PyVis to visualize network activity.</li>
            </ul>
            <p>
                Example code for a network graph:
            </p>
            <pre><code>from pyvis.network import Network

net = Network()
net.add_node(1, label="Local IP")
net.add_node(2, label="Tor Node 1")
net.add_edge(1, 2)
net.show("network.html")
            </code></pre>
            <img src="images/network_graph.jpg" alt="PyVis network graph showing Tor node connections" class="project-img">
            <p>
                <strong>Challenge</strong>: Overcrowded network graphs with large datasets.<br>
                <strong>Solution</strong>: Filtered nodes to show only high-frequency connections.
            </p>

            <h2 class="subtitle">7. Generating Forensic Reports</h2>
            <p>
                A forensic report was generated using <code>reportlab</code> to summarize findings, including detected anomalies, anti-forensic actions, and visualizations. The report included MD5/SHA256 hashes of artifacts to ensure evidential integrity.
            </p>
            <p>
                Example code for hash calculation:
            </p>
            <pre><code>import hashlib

with open("places.sqlite", "rb") as f:
    md5_hash = hashlib.md5(f.read()).hexdigest()
            </code></pre>
            <img src="images/report_preview.jpg" alt="Preview of forensic report PDF with hashes and visualizations" class="project-img">
            <p>
                <strong>Challenge</strong>: Embedding complex visualizations in PDF.<br>
                <strong>Solution</strong>: Converted Plotly plots to static images using <code>plotly.io.write_image</code>.
            </p>

            <h2 class="subtitle">8. Troubleshooting</h2>
            <p>
                Several technical issues arose during development, requiring creative solutions:
            </p>
            <table>
                <tr><th>Problem</th><th>Solution</th></tr>
                <tr><td>Corrupted Tor <code>places.sqlite</code></td><td>Validated database with <code>sqlite3.pragma_integrity_check</code></td></tr>
                <tr><td>Volatility3 plugin errors</td><td>Updated to latest version and used correct memory profile</td></tr>
                <tr><td>Missing VPN logs</td><td>Enabled verbose logging in OpenVPN configuration</td></tr>
                <tr><td>ML model overfitting</td><td>Normalized features with <code>StandardScaler</code> and tuned parameters</td></tr>
                <tr><td>Slow artifact parsing</td><td>Optimized <code>pandas</code> operations with vectorization</td></tr>
            </table>
            <img src="images/volatility_error.jpg" alt="Terminal showing Volatility3 troubleshooting output" class="project-img">

            <h2 class="subtitle">9. Useful Commands</h2>
            <p>
                These commands were critical for setup and debugging:
            </p>
            <pre><code># Check Tor Browser process
ps aux | grep tor

# Analyze memory dump with Volatility3
volatility3 -f memory.dmp windows.pslist

# Verify SQLite database
sqlite3 places.sqlite "PRAGMA integrity_check"
            </code></pre>

            <h2 class="subtitle">Why It Matters</h2>
            <p>
                Shadow Tracker showcases advanced user behavior forensics in privacy-centric environments, with applications in:
            </p>
            <ul>
                <li><strong>Cybercrime Investigations</strong>: Tracking activities in dark pools like Tor.</li>
                <li><strong>Threat Intelligence</strong>: Detecting insider threats or data exfiltration.</li>
                <li><strong>DFIR</strong>: Automating forensic analysis for faster incident response.</li>
            </ul>
            <p>
                Future enhancements could include real-time monitoring, support for other privacy tools (e.g., I2P), or integration with SIEM systems.
            </p>

            <h2 class="subtitle">Skills Demonstrated</h2>
            <ul>
                <li>Digital forensics and cybersecurity analysis.</li>
                <li>Data engineering with behavioral and time-series data.</li>
                <li>Machine learning for anomaly detection.</li>
                <li>Python programming and system integration.</li>
                <li>Technical documentation and data visualization.</li>
            </ul>

            <h2 class="subtitle">Project Timeline</h2>
            <ul>
                <li><strong>Week 1</strong>: Environment setup, Tor/VPN installation, Volatility3 configuration.</li>
                <li><strong>Week 2</strong>: Artifact parsing scripts for Tor, VPN, and memory.</li>
                <li><strong>Week 3</strong>: Behavioral profiling, anomaly detection, and anti-forensics analysis.</li>
                <li><strong>Week 4</strong>: Visualization, forensic reporting, and HTML documentation.</li>
            </ul>

            <h2 class="subtitle">Lessons Learned</h2>
            <ul>
                <li>Complexity of Tor’s artifact structure requires careful parsing and validation.</li>
                <li>Memory analysis with Volatility3 is powerful but demands precise configuration.</li>
                <li>Balancing rule-based and ML-based detection improves accuracy.</li>
                <li>Clear visualizations and reports are critical for communicating forensic findings.</li>
                <li>Ethical considerations in analyzing privacy tools require transparency.</li>
            </ul>

            <h2 class="subtitle">Conclusion</h2>
            <p>
                Shadow Tracker was a deep dive into user behavior forensics, blending cybersecurity, data analysis, and machine learning to uncover hidden digital footprints. For more details or to explore the code, visit my <a href="https://github.com/[your-username]/shadow-tracker" class="btn">GitHub repository</a> or contact me at <a href="mailto:[your-email]">[your-email]</a>. I’m eager to discuss this project or collaborate on cybersecurity challenges.
            </p>
        </div>
    </section>

    <!-- Footer -->
    <footer class="footer">
        <p>© 2025 [Your Name] | Built with Passion</p>
    </footer>

    <script src="../../assets/js/script.js"></script>
</body>
</html>
